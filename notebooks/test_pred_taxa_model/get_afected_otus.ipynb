{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2883c172",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcf8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4bd68",
   "metadata": {},
   "source": [
    "# get the afected OTUs by the corruption of silva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f856ae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed species list loaded:\n",
      "  Path: /home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/taxonomy_reference/silva-138.2/vsearch_incomplete_species_fromOTUS_predictions/removed_species_20pct_seed123.json\n",
      "  |removed_species| = 2,058\n",
      "\n",
      "True SINTAX table loaded:\n",
      "  Path: /home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/taxonomy_reference/silva-138.2/vsearch_all_OTUs/repseqs_sintax_v123.txt\n",
      "  Total OTUs in table: 111,870\n",
      "  OTUs with valid species label: 7,359\n",
      "  Affected OTUs (true species in removed list): 1,518\n",
      "  Affected fraction among OTUs with valid species: 20.63%\n",
      "\n",
      "Saved affected OTU ids to:\n",
      "  /home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/taxonomy_reference/silva-138.2/vsearch_incomplete_species_fromOTUS_predictions/affected_otu_ids_from_removed_species.txt\n",
      "  |affected_otu_ids| = 1,518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Paths (edit if needed)\n",
    "# -------------------------\n",
    "true_path = \"/home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/taxonomy_reference/silva-138.2/vsearch_all_OTUs/repseqs_sintax_v123.txt\"\n",
    "\n",
    "removed_species_path = \"/home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/taxonomy_reference/silva-138.2/vsearch_incomplete_species_fromOTUS_predictions/removed_species_20pct_seed123.json\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "RANKS = [\"k\", \"p\", \"c\", \"o\", \"f\", \"g\", \"s\"]\n",
    "\n",
    "def _clean_name(x):\n",
    "    \"\"\"Normalize a taxonomy name: remove confidence parentheses, trim, remove surrounding quotes.\"\"\"\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    # drop confidence \"(...)\" if present\n",
    "    s = s.split(\"(\", 1)[0].strip()\n",
    "    # remove surrounding single/double quotes if present\n",
    "    if len(s) >= 2 and ((s[0] == s[-1] == \"'\") or (s[0] == s[-1] == '\"')):\n",
    "        s = s[1:-1].strip()\n",
    "    return s\n",
    "\n",
    "def is_unknown(name):\n",
    "    \"\"\"Heuristic unknown detector consistent with your prior usage.\"\"\"\n",
    "    s = _clean_name(name)\n",
    "    if s == \"\":\n",
    "        return True\n",
    "    sl = s.lower()\n",
    "    return (\"__unknown\" in sl) or (sl == \"unknown\") or s.startswith(\"Unknown_\")\n",
    "\n",
    "def load_removed_species_list(json_path):\n",
    "    with open(json_path) as f:\n",
    "        items = json.load(f)\n",
    "    if not isinstance(items, list):\n",
    "        raise ValueError(\"removed_species JSON must be a list of strings.\")\n",
    "    out = set()\n",
    "    for x in items:\n",
    "        s = _clean_name(x)\n",
    "        if s:\n",
    "            out.add(s)\n",
    "    return out\n",
    "\n",
    "def drop_conf_and_extract_taxonomy(raw):\n",
    "    \"\"\"\n",
    "    Convert a raw SINTAX string into a canonical comma-separated rank:name string.\n",
    "    Handles strings like: \"k:Bacteria(1.00),p:Firmicutes(0.99),...,s:Acholeplasma_laidlawii(0.97)\"\n",
    "    \"\"\"\n",
    "    if raw is None:\n",
    "        return \"\"\n",
    "    raw = str(raw).strip()\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    # Split by ',' and keep only parts containing ':'\n",
    "    parts = []\n",
    "    for p in raw.rstrip(\";\").split(\",\"):\n",
    "        p = p.strip()\n",
    "        if \":\" not in p:\n",
    "            continue\n",
    "        r, name = p.split(\":\", 1)\n",
    "        r = r.strip()\n",
    "        name = _clean_name(name)\n",
    "        if r and name:\n",
    "            parts.append(r + \":\" + name)\n",
    "        elif r:\n",
    "            parts.append(r + \":\")\n",
    "    return \",\".join(parts)\n",
    "\n",
    "def load_true_sintax_table(path):\n",
    "    \"\"\"\n",
    "    Reads SINTAX output robustly.\n",
    "    Tries to read otu_id + taxonomy from columns [0,3] first; otherwise uses [0,1].\n",
    "    Returns df with columns: otu_id (str), taxonomy (str)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            path, sep=\"\\t\", header=None, engine=\"python\",\n",
    "            usecols=[0, 3], names=[\"otu_id\", \"taxonomy\"], dtype=str\n",
    "        )\n",
    "        df[\"taxonomy\"] = df[\"taxonomy\"].fillna(\"\").astype(str)\n",
    "        # If taxonomy column is unexpectedly empty, fallback:\n",
    "        if (df[\"taxonomy\"].str.len().sum() == 0):\n",
    "            raise ValueError(\"taxonomy column empty; fallback to raw parsing\")\n",
    "        return df\n",
    "    except Exception:\n",
    "        df_raw = pd.read_csv(\n",
    "            path, sep=\"\\t\", header=None, engine=\"python\",\n",
    "            usecols=[0, 1], names=[\"otu_id\", \"raw_sintax\"], dtype=str\n",
    "        )\n",
    "        df_raw[\"raw_sintax\"] = df_raw[\"raw_sintax\"].fillna(\"\").astype(str)\n",
    "        df_raw[\"taxonomy\"] = df_raw[\"raw_sintax\"].apply(drop_conf_and_extract_taxonomy)\n",
    "        return df_raw[[\"otu_id\", \"taxonomy\"]]\n",
    "\n",
    "def extract_species_from_taxonomy(tax_str):\n",
    "    \"\"\"\n",
    "    Extract the species name (value after 's:') from canonical \"k:...,p:...,s:Name\" string.\n",
    "    Returns \"\" if absent.\n",
    "    \"\"\"\n",
    "    if tax_str is None:\n",
    "        return \"\"\n",
    "    tax_str = str(tax_str).strip()\n",
    "    if not tax_str:\n",
    "        return \"\"\n",
    "    # Split by comma and find rank 's'\n",
    "    for part in tax_str.rstrip(\";\").split(\",\"):\n",
    "        part = part.strip()\n",
    "        if part.startswith(\"s:\"):\n",
    "            return _clean_name(part.split(\":\", 1)[1])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "removed_species = load_removed_species_list(removed_species_path)\n",
    "print(\"Removed species list loaded:\")\n",
    "print(\"  Path:\", removed_species_path)\n",
    "print(\"  |removed_species| = {:,}\".format(len(removed_species)))\n",
    "\n",
    "true_df = load_true_sintax_table(true_path)\n",
    "true_df[\"otu_id\"] = true_df[\"otu_id\"].astype(str).str.strip()\n",
    "true_df[\"taxonomy\"] = true_df[\"taxonomy\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Extract species for each OTU\n",
    "true_df[\"species_true\"] = true_df[\"taxonomy\"].apply(extract_species_from_taxonomy)\n",
    "\n",
    "# Valid species = non-empty AND not unknown-like\n",
    "valid_species_mask = (~true_df[\"species_true\"].apply(is_unknown))\n",
    "true_df_valid = true_df[valid_species_mask].copy()\n",
    "\n",
    "# Affected OTUs = valid species AND species in removed list\n",
    "affected_mask = true_df_valid[\"species_true\"].isin(removed_species)\n",
    "affected_df = true_df_valid[affected_mask].copy()\n",
    "\n",
    "# Report\n",
    "n_total = len(true_df)\n",
    "n_valid_species = len(true_df_valid)\n",
    "n_affected = len(affected_df)\n",
    "\n",
    "print(\"\\nTrue SINTAX table loaded:\")\n",
    "print(\"  Path:\", true_path)\n",
    "print(\"  Total OTUs in table: {:,}\".format(n_total))\n",
    "print(\"  OTUs with valid species label: {:,}\".format(n_valid_species))\n",
    "print(\"  Affected OTUs (true species in removed list): {:,}\".format(n_affected))\n",
    "\n",
    "if n_valid_species > 0:\n",
    "    print(\"  Affected fraction among OTUs with valid species: {:.2%}\".format(n_affected / float(n_valid_species)))\n",
    "else:\n",
    "    print(\"  Affected fraction: n/a (no valid species labels found)\")\n",
    "\n",
    "# Optional: keep the affected OTU id set for the next steps\n",
    "affected_otu_ids = set(affected_df[\"otu_id\"].astype(str).str.strip().tolist())\n",
    "\n",
    "# Optional: save for later use\n",
    "out_path = os.path.join(os.path.dirname(removed_species_path), \"affected_otu_ids_from_removed_species.txt\")\n",
    "with open(out_path, \"w\") as f:\n",
    "    for oid in sorted(affected_otu_ids):\n",
    "        f.write(str(oid) + \"\\n\")\n",
    "\n",
    "print(\"\\nSaved affected OTU ids to:\")\n",
    "print(\"  {}\".format(out_path))\n",
    "print(\"  |affected_otu_ids| = {:,}\".format(len(affected_otu_ids)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_ontology_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8fb62d",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e460e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "# --- project root & local modules (same pattern as your notebook) ---\n",
    "PROJ_ROOT = \"/home/hernan_melmoth/Documents/phd_work/otu-taxa-foundation\"\n",
    "sys.path.append(os.path.join(PROJ_ROOT, \"src\"))\n",
    "\n",
    "# Dataset root (same pattern as your notebook)\n",
    "DATASET_ROOT = \"/home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training\"\n",
    "dataset_folder_name = \"dataset_full_top999\"\n",
    "\n",
    "dataset_dir = os.path.join(\n",
    "    DATASET_ROOT,\n",
    "    \"level_97\",\n",
    "    \"silva-138.2\",\n",
    "    \"incomplete_silva_sintax\",\n",
    "    dataset_folder_name,\n",
    ")\n",
    "\n",
    "from otu_taxa.dataloaders_unk_balance_ranks import (\n",
    "    OTUTaxaDataset,\n",
    "    MaskingConfig,\n",
    "    make_collator_balanced_rank,\n",
    "    build_tax2ancestor_at_ranks,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8116855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset size: N=1836250\n",
      "[SPLIT] Train=1796250  Val=20000  Test=20000  (Total N=1836250)\n"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "ds = OTUTaxaDataset(dataset_dir)\n",
    "N = len(ds)\n",
    "print(f\"[INFO] Dataset size: N={N}\")\n",
    "\n",
    "TEST_N = min(20_000, N)\n",
    "VAL_N  = min(20_000, N - TEST_N)\n",
    "\n",
    "all_idx = list(range(N))\n",
    "random.shuffle(all_idx)\n",
    "\n",
    "test_idx  = sorted(all_idx[:TEST_N])\n",
    "val_idx   = sorted(all_idx[TEST_N:TEST_N + VAL_N])\n",
    "train_idx = sorted(all_idx[TEST_N + VAL_N:])\n",
    "\n",
    "print(f\"[SPLIT] Train={len(train_idx)}  Val={len(val_idx)}  Test={len(test_idx)}  (Total N={N})\")\n",
    "\n",
    "train_ds = Subset(ds, train_idx)\n",
    "val_ds   = Subset(ds, val_idx)\n",
    "test_ds  = Subset(ds, test_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c083d",
   "metadata": {},
   "source": [
    "# Collect OTUs per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_otus(subset):\n",
    "    otu_set = set()\n",
    "    otu_counts = Counter()\n",
    "    total_positions = 0\n",
    "\n",
    "    for rec in subset:\n",
    "        otus = rec[\"otus\"]          \n",
    "        otu_set.update(otus)\n",
    "        otu_counts.update(otus)\n",
    "        total_positions += len(otus)\n",
    "\n",
    "    return otu_set, otu_counts, total_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c37466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique OTUs in train: 62200\n",
      "Unique OTUs in test : 59446\n"
     ]
    }
   ],
   "source": [
    "train_otus, train_counts, train_pos = collect_otus(train_ds)\n",
    "test_otus,  test_counts,  test_pos  = collect_otus(test_ds)\n",
    "\n",
    "print(\"Unique OTUs in train:\", len(train_otus))\n",
    "print(\"Unique OTUs in test :\", len(test_otus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d46c8",
   "metadata": {},
   "source": [
    "# zero shot? searching unique OTUs in TEST that are not in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37dda025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen OTUs in test (not in train): 0\n",
      "Fraction of test OTUs unseen: 0.0\n"
     ]
    }
   ],
   "source": [
    "unseen_test_otus = test_otus - train_otus\n",
    "\n",
    "print(\"Unseen OTUs in test (not in train):\", len(unseen_test_otus))\n",
    "print(\"Fraction of test OTUs unseen:\",\n",
    "      len(unseen_test_otus) / len(test_otus) if test_otus else 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a672d31",
   "metadata": {},
   "source": [
    "# split groups in Train, support and query\n",
    "\n",
    "Zero-shot OTU generalization\n",
    "Question: Can the model infer taxonomy for an OTU it has never seen before? \n",
    "\n",
    "* Target OTUs are completely absent during pre training\n",
    "* OTUs appear only at test time\n",
    "* Taxonomy is masked at evaluation\n",
    "* The model must infer taxonomy using:\n",
    "* co-occurrence context\n",
    "* taxonomy structure learned from other OTUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95b9c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size N = 1836250\n",
      "OTU vocab size O = 62200\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, random\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# --- repo src (adjust if needed) ---\n",
    "PROJ_ROOT = Path(\"/home/hernan_melmoth/Documents/phd_work/otu-taxa-foundation\")\n",
    "SRC_DIR = PROJ_ROOT / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "from otu_taxa.dataloaders_unk_balanced import OTUTaxaDataset\n",
    "\n",
    "# --- dataset path (EDIT ONLY THIS) ---\n",
    "DATASET_ROOT = \"/home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training\"\n",
    "dataset_folder_name = \"dataset_full_top999\"\n",
    "\n",
    "dataset_dir = os.path.join(\n",
    "    DATASET_ROOT,\n",
    "    \"level_97\",\n",
    "    \"silva-138.2\",\n",
    "    \"incomplete_silva_sintax\",\n",
    "    dataset_folder_name,\n",
    ")\n",
    "\n",
    "ds = OTUTaxaDataset(dataset_dir)\n",
    "N = len(ds)\n",
    "print(\"Dataset size N =\", N)\n",
    "print(\"OTU vocab size O =\", ds.O)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53451af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  indexed 20000/1836250 samples...\n",
      "  indexed 40000/1836250 samples...\n",
      "  indexed 60000/1836250 samples...\n",
      "  indexed 80000/1836250 samples...\n",
      "  indexed 100000/1836250 samples...\n",
      "  indexed 120000/1836250 samples...\n",
      "  indexed 140000/1836250 samples...\n",
      "  indexed 160000/1836250 samples...\n",
      "  indexed 180000/1836250 samples...\n",
      "  indexed 200000/1836250 samples...\n",
      "  indexed 220000/1836250 samples...\n",
      "  indexed 240000/1836250 samples...\n",
      "  indexed 260000/1836250 samples...\n",
      "  indexed 280000/1836250 samples...\n",
      "  indexed 300000/1836250 samples...\n",
      "  indexed 320000/1836250 samples...\n",
      "  indexed 340000/1836250 samples...\n",
      "  indexed 360000/1836250 samples...\n",
      "  indexed 380000/1836250 samples...\n",
      "  indexed 400000/1836250 samples...\n",
      "  indexed 420000/1836250 samples...\n",
      "  indexed 440000/1836250 samples...\n",
      "  indexed 460000/1836250 samples...\n",
      "  indexed 480000/1836250 samples...\n",
      "  indexed 500000/1836250 samples...\n",
      "  indexed 520000/1836250 samples...\n",
      "  indexed 540000/1836250 samples...\n",
      "  indexed 560000/1836250 samples...\n",
      "  indexed 580000/1836250 samples...\n",
      "  indexed 600000/1836250 samples...\n",
      "  indexed 620000/1836250 samples...\n",
      "  indexed 640000/1836250 samples...\n",
      "  indexed 660000/1836250 samples...\n",
      "  indexed 680000/1836250 samples...\n",
      "  indexed 700000/1836250 samples...\n",
      "  indexed 720000/1836250 samples...\n",
      "  indexed 740000/1836250 samples...\n",
      "  indexed 760000/1836250 samples...\n",
      "  indexed 780000/1836250 samples...\n",
      "  indexed 800000/1836250 samples...\n",
      "  indexed 820000/1836250 samples...\n",
      "  indexed 840000/1836250 samples...\n",
      "  indexed 860000/1836250 samples...\n",
      "  indexed 880000/1836250 samples...\n",
      "  indexed 900000/1836250 samples...\n",
      "  indexed 920000/1836250 samples...\n",
      "  indexed 940000/1836250 samples...\n",
      "  indexed 960000/1836250 samples...\n",
      "  indexed 980000/1836250 samples...\n",
      "  indexed 1000000/1836250 samples...\n",
      "  indexed 1020000/1836250 samples...\n",
      "  indexed 1040000/1836250 samples...\n",
      "  indexed 1060000/1836250 samples...\n",
      "  indexed 1080000/1836250 samples...\n",
      "  indexed 1100000/1836250 samples...\n",
      "  indexed 1120000/1836250 samples...\n",
      "  indexed 1140000/1836250 samples...\n",
      "  indexed 1160000/1836250 samples...\n",
      "  indexed 1180000/1836250 samples...\n",
      "  indexed 1200000/1836250 samples...\n",
      "  indexed 1220000/1836250 samples...\n",
      "  indexed 1240000/1836250 samples...\n",
      "  indexed 1260000/1836250 samples...\n",
      "  indexed 1280000/1836250 samples...\n",
      "  indexed 1300000/1836250 samples...\n",
      "  indexed 1320000/1836250 samples...\n",
      "  indexed 1340000/1836250 samples...\n",
      "  indexed 1360000/1836250 samples...\n",
      "  indexed 1380000/1836250 samples...\n",
      "  indexed 1400000/1836250 samples...\n",
      "  indexed 1420000/1836250 samples...\n",
      "  indexed 1440000/1836250 samples...\n",
      "  indexed 1460000/1836250 samples...\n",
      "  indexed 1480000/1836250 samples...\n",
      "  indexed 1500000/1836250 samples...\n",
      "  indexed 1520000/1836250 samples...\n",
      "  indexed 1540000/1836250 samples...\n",
      "  indexed 1560000/1836250 samples...\n",
      "  indexed 1580000/1836250 samples...\n",
      "  indexed 1600000/1836250 samples...\n",
      "  indexed 1620000/1836250 samples...\n",
      "  indexed 1640000/1836250 samples...\n",
      "  indexed 1660000/1836250 samples...\n",
      "  indexed 1680000/1836250 samples...\n",
      "  indexed 1700000/1836250 samples...\n",
      "  indexed 1720000/1836250 samples...\n",
      "  indexed 1740000/1836250 samples...\n",
      "  indexed 1760000/1836250 samples...\n",
      "  indexed 1780000/1836250 samples...\n",
      "  indexed 1800000/1836250 samples...\n",
      "  indexed 1820000/1836250 samples...\n",
      "Indexed OTUs: 62200\n",
      "Indexed samples: 1836250\n"
     ]
    }
   ],
   "source": [
    "def build_otu_to_sample_index(ds, max_samples=None, seed=123):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      otu_to_samples: dict[int, set[int]] mapping OTU -> set of sample indices where it appears\n",
    "      sample_sizes: np.array length N with number of OTUs per sample (optional utility)\n",
    "    \"\"\"\n",
    "    N = len(ds)\n",
    "    n = N if max_samples is None else min(N, max_samples)\n",
    "\n",
    "    otu_to_samples = defaultdict(set)\n",
    "    sample_sizes = np.zeros(n, dtype=np.int32)\n",
    "\n",
    "    for i in range(n):\n",
    "        rec = ds[i]\n",
    "        otus = rec[\"otus\"]\n",
    "        sample_sizes[i] = len(otus)\n",
    "        for o in otus:\n",
    "            otu_to_samples[int(o)].add(i)\n",
    "\n",
    "        if (i + 1) % 20000 == 0:\n",
    "            print(f\"  indexed {i+1}/{n} samples...\")\n",
    "\n",
    "    return otu_to_samples, sample_sizes\n",
    "\n",
    "# Build full index (can be heavy). If too slow, set max_samples=200_000 for a pilot.\n",
    "otu_to_samples, sample_sizes = build_otu_to_sample_index(ds, max_samples=None)\n",
    "\n",
    "print(\"Indexed OTUs:\", len(otu_to_samples))\n",
    "print(\"Indexed samples:\", len(sample_sizes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d68dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>pretrain_pool_mean</th>\n",
       "      <th>pretrain_pool_frac_mean</th>\n",
       "      <th>heldout_pool_mean</th>\n",
       "      <th>heldout_pool_frac_mean</th>\n",
       "      <th>support_pool_samples_mean</th>\n",
       "      <th>query_pool_samples_mean</th>\n",
       "      <th>otus_with_at_least_k_mean</th>\n",
       "      <th>max_supported_otus_at_k_mean</th>\n",
       "      <th>otu_count_min_mean</th>\n",
       "      <th>otu_count_median_mean</th>\n",
       "      <th>otu_count_max_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1777482.95</td>\n",
       "      <td>0.967996</td>\n",
       "      <td>58767.05</td>\n",
       "      <td>0.032004</td>\n",
       "      <td>5876.70</td>\n",
       "      <td>52890.35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12125.25</td>\n",
       "      <td>199.80</td>\n",
       "      <td>1570.85</td>\n",
       "      <td>37844.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1761326.30</td>\n",
       "      <td>0.959197</td>\n",
       "      <td>74923.70</td>\n",
       "      <td>0.040803</td>\n",
       "      <td>7492.20</td>\n",
       "      <td>67431.50</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15816.30</td>\n",
       "      <td>99.05</td>\n",
       "      <td>1458.55</td>\n",
       "      <td>33574.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1641699.50</td>\n",
       "      <td>0.894050</td>\n",
       "      <td>194550.50</td>\n",
       "      <td>0.105950</td>\n",
       "      <td>19455.05</td>\n",
       "      <td>175095.45</td>\n",
       "      <td>50.0</td>\n",
       "      <td>44292.10</td>\n",
       "      <td>58.80</td>\n",
       "      <td>1191.55</td>\n",
       "      <td>62955.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1484067.65</td>\n",
       "      <td>0.808206</td>\n",
       "      <td>352182.35</td>\n",
       "      <td>0.191794</td>\n",
       "      <td>35218.30</td>\n",
       "      <td>316964.05</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88666.75</td>\n",
       "      <td>38.25</td>\n",
       "      <td>1144.00</td>\n",
       "      <td>95135.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     K  pretrain_pool_mean  pretrain_pool_frac_mean  heldout_pool_mean  \\\n",
       "0   10          1777482.95                 0.967996           58767.05   \n",
       "1   20          1761326.30                 0.959197           74923.70   \n",
       "2   50          1641699.50                 0.894050          194550.50   \n",
       "3  100          1484067.65                 0.808206          352182.35   \n",
       "\n",
       "   heldout_pool_frac_mean  support_pool_samples_mean  query_pool_samples_mean  \\\n",
       "0                0.032004                    5876.70                 52890.35   \n",
       "1                0.040803                    7492.20                 67431.50   \n",
       "2                0.105950                   19455.05                175095.45   \n",
       "3                0.191794                   35218.30                316964.05   \n",
       "\n",
       "   otus_with_at_least_k_mean  max_supported_otus_at_k_mean  \\\n",
       "0                       10.0                      12125.25   \n",
       "1                       20.0                      15816.30   \n",
       "2                       50.0                      44292.10   \n",
       "3                      100.0                      88666.75   \n",
       "\n",
       "   otu_count_min_mean  otu_count_median_mean  otu_count_max_mean  \n",
       "0              199.80                1570.85            37844.05  \n",
       "1               99.05                1458.55            33574.35  \n",
       "2               58.80                1191.55            62955.10  \n",
       "3               38.25                1144.00            95135.75  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def analyze_holdout_set_for_fewshot(\n",
    "    otu_to_samples,\n",
    "    heldout_otus,\n",
    "    N_samples,\n",
    "    *,\n",
    "    k_shot: int = 5,\n",
    "    support_frac: float = 0.10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reports:\n",
    "      - pretrain_pool: samples with NO heldout OTUs (usable for retraining)\n",
    "      - heldout_pool: samples with >=1 heldout OTU (usable to build support/query)\n",
    "      - few-shot feasibility proxies:\n",
    "          * max_supported_otus_at_k: upper bound = sum_o floor(count_o / k)\n",
    "          * otus_with_at_least_k: number of heldout OTUs that appear in >=k samples\n",
    "      - sample-level support/query sizes if you split heldout_pool by support_frac\n",
    "    \"\"\"\n",
    "    heldout_otus = list(map(int, heldout_otus))\n",
    "\n",
    "    # sample indices that contain >=1 heldout OTU\n",
    "    heldout_samples = set()\n",
    "    per_otu_counts = []\n",
    "    otus_with_at_least_k = 0\n",
    "    max_supported_otus_at_k = 0\n",
    "\n",
    "    for o in heldout_otus:\n",
    "        sset = otu_to_samples.get(o, set())\n",
    "        c = len(sset)\n",
    "        per_otu_counts.append(c)\n",
    "        heldout_samples |= sset\n",
    "        if c >= k_shot:\n",
    "            otus_with_at_least_k += 1\n",
    "        max_supported_otus_at_k += (c // k_shot)\n",
    "\n",
    "    heldout_pool_n = len(heldout_samples)\n",
    "    pretrain_pool_n = N_samples - heldout_pool_n\n",
    "\n",
    "    # sample-level split of heldout pool into support/query\n",
    "    support_n = int(round(heldout_pool_n * support_frac))\n",
    "    query_n = heldout_pool_n - support_n\n",
    "\n",
    "    # useful summary stats of OTU occurrence counts\n",
    "    per_otu_counts = np.array(per_otu_counts, dtype=np.int64)\n",
    "    if len(per_otu_counts) > 0:\n",
    "        c_min = int(per_otu_counts.min())\n",
    "        c_med = int(np.median(per_otu_counts))\n",
    "        c_max = int(per_otu_counts.max())\n",
    "    else:\n",
    "        c_min = c_med = c_max = 0\n",
    "\n",
    "    return {\n",
    "        \"K\": len(heldout_otus),\n",
    "        \"k_shot\": int(k_shot),\n",
    "        \"support_frac\": float(support_frac),\n",
    "\n",
    "        # pools\n",
    "        \"pretrain_pool\": int(pretrain_pool_n),\n",
    "        \"pretrain_pool_frac\": pretrain_pool_n / max(1, N_samples),\n",
    "        \"heldout_pool\": int(heldout_pool_n),\n",
    "        \"heldout_pool_frac\": heldout_pool_n / max(1, N_samples),\n",
    "\n",
    "        # sample split within heldout pool\n",
    "        \"support_pool_samples\": int(support_n),\n",
    "        \"query_pool_samples\": int(query_n),\n",
    "\n",
    "        # few-shot feasibility proxies\n",
    "        \"otus_with_at_least_k\": int(otus_with_at_least_k),\n",
    "        \"max_supported_otus_at_k\": int(max_supported_otus_at_k),\n",
    "\n",
    "        # OTU occurrence stats (within heldout pool)\n",
    "        \"otu_count_min\": c_min,\n",
    "        \"otu_count_median\": c_med,\n",
    "        \"otu_count_max\": c_max,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_trials_random_K_fewshot(\n",
    "    otu_to_samples,\n",
    "    N_samples,\n",
    "    K_list,\n",
    "    *,\n",
    "    k_shot: int = 5,\n",
    "    support_frac: float = 0.10,\n",
    "    n_trials: int = 20,\n",
    "    seed: int = 123,\n",
    "    pool=None\n",
    "):\n",
    "    rng = random.Random(seed)\n",
    "    if pool is None:\n",
    "        pool = sorted(list(otu_to_samples.keys()))\n",
    "    else:\n",
    "        pool = sorted(list(pool))\n",
    "\n",
    "    rows = []\n",
    "    for K in map(int, K_list):\n",
    "        for t in range(n_trials):\n",
    "            heldout = rng.sample(pool, k=min(K, len(pool)))\n",
    "            stats = analyze_holdout_set_for_fewshot(\n",
    "                otu_to_samples,\n",
    "                heldout,\n",
    "                N_samples,\n",
    "                k_shot=k_shot,\n",
    "                support_frac=support_frac,\n",
    "            )\n",
    "            stats[\"trial\"] = t\n",
    "            rows.append(stats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "K_list = [10, 20, 50, 100]\n",
    "k_shot = 5          # try 2 / 5 / 10\n",
    "support_frac = 0.10 # or 0.05\n",
    "\n",
    "df = run_trials_random_K_fewshot(\n",
    "    otu_to_samples,\n",
    "    N_samples=N,\n",
    "    K_list=K_list,\n",
    "    k_shot=k_shot,\n",
    "    support_frac=support_frac,\n",
    "    n_trials=20,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "summary = df.groupby(\"K\").agg(\n",
    "    pretrain_pool_mean=(\"pretrain_pool\", \"mean\"),\n",
    "    pretrain_pool_frac_mean=(\"pretrain_pool_frac\", \"mean\"),\n",
    "    heldout_pool_mean=(\"heldout_pool\", \"mean\"),\n",
    "    heldout_pool_frac_mean=(\"heldout_pool_frac\", \"mean\"),\n",
    "\n",
    "    support_pool_samples_mean=(\"support_pool_samples\", \"mean\"),\n",
    "    query_pool_samples_mean=(\"query_pool_samples\", \"mean\"),\n",
    "\n",
    "    otus_with_at_least_k_mean=(\"otus_with_at_least_k\", \"mean\"),\n",
    "    max_supported_otus_at_k_mean=(\"max_supported_otus_at_k\", \"mean\"),\n",
    "\n",
    "    otu_count_min_mean=(\"otu_count_min\", \"mean\"),\n",
    "    otu_count_median_mean=(\"otu_count_median\", \"mean\"),\n",
    "    otu_count_max_mean=(\"otu_count_max\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570db27",
   "metadata": {},
   "source": [
    "# chossing 50 (20 trials) OTUs to k-shot: test: 1641699,  heldout_pool = 194550.50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fbbb29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HELDOUT OTUs] K=50 seed=123\n",
      "preview: [109, 432, 1391, 2500, 2876, 3401, 3431, 4579, 5713, 5741]\n",
      "[POOLS] pretrain_samples (no heldout OTUs): 1561830 (0.8506)\n",
      "[POOLS] heldout_samples (>=1 heldout OTU): 274420 (0.1494)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_size</th>\n",
       "      <th>support_pool_size</th>\n",
       "      <th>k_shot</th>\n",
       "      <th>feasible_otus</th>\n",
       "      <th>support_unique_samples</th>\n",
       "      <th>support_per_otu_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>254420</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>254420</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>499</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>254420</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>997</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>254420</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2492</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>254420</td>\n",
       "      <td>100</td>\n",
       "      <td>48</td>\n",
       "      <td>4768</td>\n",
       "      <td>4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000</td>\n",
       "      <td>224420</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>224420</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50000</td>\n",
       "      <td>224420</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50000</td>\n",
       "      <td>224420</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2489</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50000</td>\n",
       "      <td>224420</td>\n",
       "      <td>100</td>\n",
       "      <td>48</td>\n",
       "      <td>4763</td>\n",
       "      <td>4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100000</td>\n",
       "      <td>174420</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>248</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100000</td>\n",
       "      <td>174420</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>497</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100000</td>\n",
       "      <td>174420</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>995</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100000</td>\n",
       "      <td>174420</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>2390</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100000</td>\n",
       "      <td>174420</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>4654</td>\n",
       "      <td>4700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_size  support_pool_size  k_shot  feasible_otus  \\\n",
       "0        20000             254420       5             50   \n",
       "1        20000             254420      10             50   \n",
       "2        20000             254420      20             50   \n",
       "3        20000             254420      50             50   \n",
       "4        20000             254420     100             48   \n",
       "5        50000             224420       5             50   \n",
       "6        50000             224420      10             50   \n",
       "7        50000             224420      20             50   \n",
       "8        50000             224420      50             50   \n",
       "9        50000             224420     100             48   \n",
       "10      100000             174420       5             50   \n",
       "11      100000             174420      10             50   \n",
       "12      100000             174420      20             50   \n",
       "13      100000             174420      50             48   \n",
       "14      100000             174420     100             47   \n",
       "\n",
       "    support_unique_samples  support_per_otu_total  \n",
       "0                      250                    250  \n",
       "1                      499                    500  \n",
       "2                      997                   1000  \n",
       "3                     2492                   2500  \n",
       "4                     4768                   4800  \n",
       "5                      250                    250  \n",
       "6                      500                    500  \n",
       "7                     1000                   1000  \n",
       "8                     2489                   2500  \n",
       "9                     4763                   4800  \n",
       "10                     248                    250  \n",
       "11                     497                    500  \n",
       "12                     995                   1000  \n",
       "13                    2390                   2400  \n",
       "14                    4654                   4700  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Fix heldout OTUs (K=50)\n",
    "# -----------------------------\n",
    "K_OTUS = 50\n",
    "SEED_OTUS = 123\n",
    "\n",
    "otu_pool = sorted(list(otu_to_samples.keys()))\n",
    "rng = random.Random(SEED_OTUS)\n",
    "heldout_otus_50 = set(rng.sample(otu_pool, k=K_OTUS))\n",
    "\n",
    "print(f\"[HELDOUT OTUs] K={len(heldout_otus_50)} seed={SEED_OTUS}\")\n",
    "print(\"preview:\", sorted(list(heldout_otus_50))[:10])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build heldout sample pool + pretrain pool sizes\n",
    "# -----------------------------\n",
    "def heldout_sample_pool(otu_to_samples, heldout_otus):\n",
    "    s = set()\n",
    "    for o in heldout_otus:\n",
    "        s |= otu_to_samples.get(int(o), set())\n",
    "    return s\n",
    "\n",
    "heldout_samples = heldout_sample_pool(otu_to_samples, heldout_otus_50)\n",
    "pretrain_samples = set(range(N)) - heldout_samples\n",
    "\n",
    "print(f\"[POOLS] pretrain_samples (no heldout OTUs): {len(pretrain_samples)} ({len(pretrain_samples)/N:.4f})\")\n",
    "print(f\"[POOLS] heldout_samples (>=1 heldout OTU): {len(heldout_samples)} ({len(heldout_samples)/N:.4f})\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Make a fixed query set (by size), and a support pool\n",
    "# -----------------------------\n",
    "def make_fixed_query_split(heldout_samples, query_size, seed=123):\n",
    "    rng = random.Random(seed)\n",
    "    pool = list(heldout_samples)\n",
    "    rng.shuffle(pool)\n",
    "    q = set(pool[:min(query_size, len(pool))])\n",
    "    p = set(pool[min(query_size, len(pool)):])\n",
    "    return q, p\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) For a given k, sample k support examples per OTU from the support pool\n",
    "#     (query stays fixed; support comes only from support_pool)\n",
    "# -----------------------------\n",
    "def sample_support_k_per_otu(\n",
    "    otu_to_samples,\n",
    "    heldout_otus,\n",
    "    support_pool,\n",
    "    k_shot,\n",
    "    seed=123,\n",
    "):\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    support_idx = set()\n",
    "    feasible_otus = 0\n",
    "    per_otu_chosen = {}  # optional: for debugging / reproducibility\n",
    "\n",
    "    support_pool = set(support_pool)\n",
    "\n",
    "    for o in sorted(map(int, heldout_otus)):\n",
    "        candidates = list(otu_to_samples.get(o, set()) & support_pool)\n",
    "        if len(candidates) < k_shot:\n",
    "            continue\n",
    "        rng.shuffle(candidates)\n",
    "        chosen = candidates[:k_shot]\n",
    "        per_otu_chosen[o] = chosen\n",
    "        support_idx |= set(chosen)\n",
    "        feasible_otus += 1\n",
    "\n",
    "    return support_idx, feasible_otus, per_otu_chosen\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Explore multiple query sizes, but keep query fixed per size\n",
    "#    Then within each query size, compare k-shot supports\n",
    "# -----------------------------\n",
    "QUERY_SIZES = [20_000, 50_000, 100_000]   # change as you like\n",
    "K_SHOTS = [5, 10, 20, 50, 100]\n",
    "\n",
    "SEED_QUERY = 999   # ensures query split reproducible\n",
    "SEED_SUPPORT = 2024\n",
    "\n",
    "rows = []\n",
    "for qsize in QUERY_SIZES:\n",
    "    query_set, support_pool = make_fixed_query_split(heldout_samples, query_size=qsize, seed=SEED_QUERY)\n",
    "\n",
    "    for k in K_SHOTS:\n",
    "        support_set, feasible_otus, _ = sample_support_k_per_otu(\n",
    "            otu_to_samples,\n",
    "            heldout_otus_50,\n",
    "            support_pool,\n",
    "            k_shot=k,\n",
    "            seed=SEED_SUPPORT,\n",
    "        )\n",
    "\n",
    "        rows.append({\n",
    "            \"query_size\": int(len(query_set)),          # exact (in case pool smaller)\n",
    "            \"support_pool_size\": int(len(support_pool)),\n",
    "            \"k_shot\": int(k),\n",
    "            \"feasible_otus\": int(feasible_otus),        # OTUs with >=k candidates in support_pool\n",
    "            \"support_unique_samples\": int(len(support_set)),\n",
    "            \"support_per_otu_total\": int(feasible_otus * k),  # requested examples (not unique)\n",
    "        })\n",
    "\n",
    "df_support = pd.DataFrame(rows).sort_values([\"query_size\", \"k_shot\"]).reset_index(drop=True)\n",
    "df_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f02cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "QUERY SET SIZE (fixed): 20,000 samples\n",
      "Available support pool size: 254,420 samples\n",
      "------------------------------------------------------------------------------------------\n",
      " k support / OTU | OTUs with ≥k samples |   unique support samples\n",
      "------------------------------------------------------------------------------------------\n",
      "               5 |                   50 |                      250\n",
      "              10 |                   50 |                      499\n",
      "              20 |                   50 |                      997\n",
      "              50 |                   50 |                    2,492\n",
      "             100 |                   48 |                    4,768\n",
      "==========================================================================================\n",
      "\n",
      "==========================================================================================\n",
      "QUERY SET SIZE (fixed): 50,000 samples\n",
      "Available support pool size: 224,420 samples\n",
      "------------------------------------------------------------------------------------------\n",
      " k support / OTU | OTUs with ≥k samples |   unique support samples\n",
      "------------------------------------------------------------------------------------------\n",
      "               5 |                   50 |                      250\n",
      "              10 |                   50 |                      500\n",
      "              20 |                   50 |                    1,000\n",
      "              50 |                   50 |                    2,489\n",
      "             100 |                   48 |                    4,763\n",
      "==========================================================================================\n",
      "\n",
      "==========================================================================================\n",
      "QUERY SET SIZE (fixed): 100,000 samples\n",
      "Available support pool size: 174,420 samples\n",
      "------------------------------------------------------------------------------------------\n",
      " k support / OTU | OTUs with ≥k samples |   unique support samples\n",
      "------------------------------------------------------------------------------------------\n",
      "               5 |                   50 |                      248\n",
      "              10 |                   50 |                      497\n",
      "              20 |                   50 |                      995\n",
      "              50 |                   48 |                    2,390\n",
      "             100 |                   47 |                    4,654\n",
      "==========================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_support_summary(df):\n",
    "    for qsize in sorted(df[\"query_size\"].unique()):\n",
    "        sub = df[df[\"query_size\"] == qsize]\n",
    "\n",
    "        print(\"=\" * 90)\n",
    "        print(f\"QUERY SET SIZE (fixed): {qsize:,} samples\")\n",
    "        print(f\"Available support pool size: {int(sub['support_pool_size'].iloc[0]):,} samples\")\n",
    "        print(\"-\" * 90)\n",
    "        print(\n",
    "            f\"{'k support / OTU':>16} | \"\n",
    "            f\"{'OTUs with ≥k samples':>20} | \"\n",
    "            f\"{'unique support samples':>24}\"\n",
    "        )\n",
    "        print(\"-\" * 90)\n",
    "\n",
    "        for _, r in sub.iterrows():\n",
    "            print(\n",
    "                f\"{r['k_shot']:>16} | \"\n",
    "                f\"{r['feasible_otus']:>20} | \"\n",
    "                f\"{r['support_unique_samples']:>24,}\"\n",
    "            )\n",
    "\n",
    "        print(\"=\" * 90)\n",
    "        print()\n",
    "\n",
    "pretty_print_support_summary(df_support)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_ontology_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

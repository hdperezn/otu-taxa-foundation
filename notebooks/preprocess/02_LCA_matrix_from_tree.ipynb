{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2695dc1",
   "metadata": {},
   "source": [
    "# Build LCA Distance Matrix (taxonomy tree)\n",
    "\n",
    "This notebook computes an LCA-based edge distance matrix D for the induced taxonomy tree used by the OTU+Taxa foundation model.\n",
    "\n",
    "Inputs (dataset folder):\n",
    "\n",
    "* taxonomy_vocab.json: list of all taxonomy nodes (base nodes only). Index order defines matrix row/col order.\n",
    "* taxonomy_nested.json: nested dictionary representing the induced taxonomy tree structure.\n",
    "\n",
    "Output:\n",
    "\n",
    "* lca_distance_edges.npy: integer matrix D where\n",
    "* D[i,j] = depth(i) + depth(j) - 2*depth(lca(i,j)) \n",
    "(number of edges in the shortest path between nodes i and j).\n",
    "\n",
    "Notes:\n",
    "\n",
    "We compute LCA using binary lifting from parent pointers derived from taxonomy_nested.json.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a7e01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_DIR = /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_silva_sintax/dataset_full_top999\n",
      "VOCAB_PATH  = /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_silva_sintax/dataset_full_top999/taxonomy_vocab.json\n",
      "NESTED_PATH = /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_silva_sintax/dataset_full_top999/taxonomy_nested.json\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Dataset directory (processed artifacts live OUTSIDE the repo)\n",
    "# ------------------------------------------------------------\n",
    "DATASET_DIR = Path(\n",
    "    \"/home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training\"\n",
    "    \"/level_97/silva-138.2/incomplete_silva_sintax/dataset_full_top999\"\n",
    ")\n",
    "\n",
    "VOCAB_PATH  = DATASET_DIR / \"taxonomy_vocab.json\"\n",
    "NESTED_PATH = DATASET_DIR / \"taxonomy_nested.json\"\n",
    "\n",
    "assert VOCAB_PATH.exists(), f\"Missing: {VOCAB_PATH}\"\n",
    "assert NESTED_PATH.exists(), f\"Missing: {NESTED_PATH}\"\n",
    "\n",
    "print(\"DATASET_DIR =\", DATASET_DIR)\n",
    "print(\"VOCAB_PATH  =\", VOCAB_PATH)\n",
    "print(\"NESTED_PATH =\", NESTED_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9154e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N taxonomy nodes = 6929\n",
      "Example vocab entries: ['c:028H05-P-BN-P5', 'c:055B07-P-DI-P58', 'c:113B434', 'c:AB64A-17', 'c:AEGEAN-245']\n",
      "Top-level keys in nested tree: ['k:Bacteria', 'k:Archaea']\n"
     ]
    }
   ],
   "source": [
    "taxonomy_vocab = json.load(open(VOCAB_PATH, \"r\"))\n",
    "tax2idx = {t: i for i, t in enumerate(taxonomy_vocab)}\n",
    "N = len(taxonomy_vocab)\n",
    "\n",
    "taxonomy_nested = json.load(open(NESTED_PATH, \"r\"))\n",
    "\n",
    "print(\"N taxonomy nodes =\", N)\n",
    "print(\"Example vocab entries:\", taxonomy_vocab[:5])\n",
    "print(\"Top-level keys in nested tree:\", list(taxonomy_nested.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8828afca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top-level roots = 3\n",
      "First 10 root nodes: ['k:Archaea', 'k:Bacteria', 'k:UNK']\n",
      "Depth computed for all nodes.\n",
      "Depth min/max: 0 6\n",
      "Binary lifting table shape: (4, 6929)\n",
      "Number of components = 3\n"
     ]
    }
   ],
   "source": [
    "def build_parent_children_from_nested(taxonomy_nested, tax2idx):\n",
    "    \"\"\"\n",
    "    Derive parent pointers and children adjacency from taxonomy_nested.json.\n",
    "    The nested dict should use the same node-name strings as taxonomy_vocab.json.\n",
    "    \"\"\"\n",
    "    N = len(tax2idx)\n",
    "    parent = np.full(N, -1, dtype=np.int32)\n",
    "    children = [[] for _ in range(N)]\n",
    "\n",
    "    def dfs(subtree: dict, parent_name=None):\n",
    "        for name, child_dict in subtree.items():\n",
    "            if name not in tax2idx:\n",
    "                # If taxonomy_nested was built from taxonomy_vocab, this should not happen.\n",
    "                continue\n",
    "\n",
    "            i = tax2idx[name]\n",
    "\n",
    "            if parent_name is not None and parent_name in tax2idx:\n",
    "                p = tax2idx[parent_name]\n",
    "                parent[i] = p\n",
    "                children[p].append(i)\n",
    "\n",
    "            if isinstance(child_dict, dict) and child_dict:\n",
    "                dfs(child_dict, parent_name=name)\n",
    "\n",
    "    # Forest: multiple top-level clades are allowed; their parent stays -1\n",
    "    dfs(taxonomy_nested, parent_name=None)\n",
    "\n",
    "    return parent, children\n",
    "\n",
    "\n",
    "parent, children = build_parent_children_from_nested(taxonomy_nested, tax2idx)\n",
    "\n",
    "roots = np.where(parent == -1)[0].tolist()\n",
    "print(\"Number of top-level roots =\", len(roots))\n",
    "print(\"First 10 root nodes:\", [taxonomy_vocab[i] for i in roots[:10]])\n",
    "\n",
    "def compute_depth(children, roots, parent):\n",
    "    \"\"\"\n",
    "    Compute BFS depths for all nodes reachable from roots.\n",
    "    Any unreachable nodes (e.g., appended k:UNK) are assigned depth=0\n",
    "    and treated as singleton components.\n",
    "    \"\"\"\n",
    "    N = len(children)\n",
    "    depth = np.full(N, -1, dtype=np.int32)\n",
    "\n",
    "    q = deque()\n",
    "    for r in roots:\n",
    "        depth[r] = 0\n",
    "        q.append(r)\n",
    "\n",
    "    while q:\n",
    "        u = q.popleft()\n",
    "        for v in children[u]:\n",
    "            depth[v] = depth[u] + 1\n",
    "            q.append(v)\n",
    "\n",
    "    # Unreachable nodes: assign depth=0 (singleton components)\n",
    "    # (We keep parent as -1; root_id will set root to itself.)\n",
    "    bad = np.where(depth < 0)[0]\n",
    "    if bad.size > 0:\n",
    "        depth[bad] = 0\n",
    "\n",
    "    return depth\n",
    "\n",
    "\n",
    "depth = compute_depth(children, roots, parent)\n",
    "\n",
    "if (depth < 0).any():\n",
    "    bad = np.where(depth < 0)[0]\n",
    "    print(\"WARNING: some nodes unreachable from roots (unexpected). Count:\", len(bad))\n",
    "    print(\"Examples:\", [taxonomy_vocab[i] for i in bad[:10]])\n",
    "else:\n",
    "    print(\"Depth computed for all nodes.\")\n",
    "    print(\"Depth min/max:\", int(depth.min()), int(depth.max()))\n",
    "def build_binary_lifting(parent, depth):\n",
    "    \"\"\"\n",
    "    Build binary lifting table for fast LCA.\n",
    "    \"\"\"\n",
    "    N = len(parent)\n",
    "    max_depth = int(depth.max()) if N else 0\n",
    "    LOG = int(np.ceil(np.log2(max_depth + 1))) + 1\n",
    "\n",
    "    up = np.full((LOG, N), -1, dtype=np.int32)\n",
    "    up[0, :] = parent\n",
    "\n",
    "    for k in range(1, LOG):\n",
    "        prev = up[k - 1]\n",
    "        up[k, :] = np.where(prev != -1, up[k - 1, prev], -1)\n",
    "\n",
    "    return up\n",
    "\n",
    "\n",
    "up = build_binary_lifting(parent, depth)\n",
    "print(\"Binary lifting table shape:\", up.shape)\n",
    "\n",
    "def compute_component_root(parent, depth):\n",
    "    \"\"\"\n",
    "    root_id[i] = top-level root index for node i.\n",
    "    For unreachable/sentinel nodes (depth was originally -1, now set to 0),\n",
    "    if parent[i] == -1 and node is not in the main forest, we map root_id[i] = i\n",
    "    (singleton component).\n",
    "    \"\"\"\n",
    "    N = len(parent)\n",
    "    root_id = np.full(N, -1, dtype=np.int32)\n",
    "\n",
    "    for i in range(N):\n",
    "        # Singleton/sentinel: parent=-1 and (effectively) not attached to forest\n",
    "        # We detect this by: parent[i]==-1 and i not in any child list;\n",
    "        # but easiest robust rule: if parent chain is empty, root is itself.\n",
    "        x = i\n",
    "        while parent[x] != -1:\n",
    "            x = parent[x]\n",
    "        root_id[i] = x\n",
    "\n",
    "    return root_id\n",
    "\n",
    "\n",
    "root_id = compute_component_root(parent, depth)\n",
    "\n",
    "# Sanity: count distinct components\n",
    "unique_roots = np.unique(root_id)\n",
    "print(\"Number of components =\", len(unique_roots))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed85184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LCA distance matrix: 100%|██████████| 6929/6929 [01:36<00:00, 71.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D shape: (6929, 6929) dtype: int16\n",
      "Finite entries: 42836115 min: 0 max: 12\n",
      "Missing (=-1) entries: 5174926\n"
     ]
    }
   ],
   "source": [
    "def lca(u, v, up, depth, root_id):\n",
    "    \"\"\"\n",
    "    Lowest Common Ancestor of nodes u and v.\n",
    "    Returns:\n",
    "      - node index of LCA, or -1 if u and v are in different components.\n",
    "    \"\"\"\n",
    "    if root_id[u] != root_id[v]:\n",
    "        return -1\n",
    "\n",
    "    if depth[u] < depth[v]:\n",
    "        u, v = v, u\n",
    "\n",
    "    # Lift u to the depth of v\n",
    "    diff = int(depth[u] - depth[v])\n",
    "    k = 0\n",
    "    while diff:\n",
    "        if diff & 1:\n",
    "            u = up[k, u]\n",
    "        diff >>= 1\n",
    "        k += 1\n",
    "\n",
    "    if u == v:\n",
    "        return u\n",
    "\n",
    "    # Lift both until their parents match\n",
    "    for k in range(up.shape[0] - 1, -1, -1):\n",
    "        uu = up[k, u]\n",
    "        vv = up[k, v]\n",
    "        if uu != vv:\n",
    "            u, v = uu, vv\n",
    "\n",
    "    return up[0, u]\n",
    "\n",
    "def build_lca_distance_matrix(depth, up, root_id, dtype=np.int16):\n",
    "    N = len(depth)\n",
    "    D = np.full((N, N), -1, dtype=dtype)\n",
    "    np.fill_diagonal(D, 0)\n",
    "\n",
    "    for i in tqdm(range(N), desc=\"Building LCA distance matrix\"):\n",
    "        for j in range(i + 1, N):\n",
    "            a = lca(i, j, up, depth, root_id)\n",
    "            if a == -1:\n",
    "                dist = -1\n",
    "            else:\n",
    "                dist = int(depth[i] + depth[j] - 2 * depth[a])\n",
    "            D[i, j] = D[j, i] = dist\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "D = build_lca_distance_matrix(depth, up, root_id, dtype=np.int16)\n",
    "\n",
    "finite = D[D >= 0]\n",
    "print(\"D shape:\", D.shape, \"dtype:\", D.dtype)\n",
    "print(\"Finite entries:\", finite.size, \"min:\", int(finite.min()), \"max:\", int(finite.max()))\n",
    "print(\"Missing (=-1) entries:\", int((D < 0).sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc427beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree artifacts will be saved in: /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_silva_sintax/dataset_full_top999/tree_artifacts\n",
      "Saved LCA distance matrix to: /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_silva_sintax/dataset_full_top999/tree_artifacts/lca_distance_edges.npy\n",
      "Saved structural tree arrays:\n",
      " - parent.npy\n",
      " - depth.npy\n",
      " - root_id.npy\n"
     ]
    }
   ],
   "source": [
    "TREE_DIR = DATASET_DIR / \"tree_artifacts\"\n",
    "TREE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Tree artifacts will be saved in:\", TREE_DIR)\n",
    "lca_path = TREE_DIR / \"lca_distance_edges.npy\"\n",
    "np.save(lca_path, D)\n",
    "print(\"Saved LCA distance matrix to:\", lca_path)\n",
    "np.save(TREE_DIR / \"parent.npy\", parent)\n",
    "np.save(TREE_DIR / \"depth.npy\", depth)\n",
    "np.save(TREE_DIR / \"root_id.npy\", root_id)\n",
    "\n",
    "print(\"Saved structural tree arrays:\")\n",
    "print(\" - parent.npy\")\n",
    "print(\" - depth.npy\")\n",
    "print(\" - root_id.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0e35fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_silva_sintax/dataset_full_top999/tree_artifacts/README.md\n"
     ]
    }
   ],
   "source": [
    "readme_path = TREE_DIR / \"README.md\"\n",
    "with open(readme_path, \"w\") as f:\n",
    "    f.write(\n",
    "        \"# Tree Artifacts\\n\\n\"\n",
    "        \"This folder contains **derived taxonomy tree artifacts** computed from\\n\"\n",
    "        \"`taxonomy_nested.json` and `taxonomy_vocab.json`.\\n\\n\"\n",
    "        \"These files are **not raw dataset definitions**. They encode structural\\n\"\n",
    "        \"properties of the taxonomy hierarchy that are required by the OTU+Taxa\\n\"\n",
    "        \"foundation model for hierarchical operations, constraints, and regularization.\\n\\n\"\n",
    "        \"All arrays in this folder are **index-aligned with `taxonomy_vocab.json`**.\\n\"\n",
    "        \"That is, index `i` in any array corresponds to `taxonomy_vocab[i]`.\\n\\n\"\n",
    "        \"## Files\\n\\n\"\n",
    "        \"- `parent.npy`\\n\"\n",
    "        \"  Parent index of each taxonomy node in the tree (`-1` indicates the synthetic root).\\n\\n\"\n",
    "        \"- `depth.npy`\\n\"\n",
    "        \"  Depth of each taxonomy node measured from the root of its connected component.\\n\\n\"\n",
    "        \"- `root_id.npy`\\n\"\n",
    "        \"  Identifier of the top-level component (root clade) each node belongs to.\\n\\n\"\n",
    "        \"- `lca_distance_edges.npy`\\n\"\n",
    "        \"  Symmetric matrix of topological distances between taxonomy nodes,\\n\"\n",
    "        \"  computed as the number of edges between two nodes via their lowest common ancestor (LCA).\\n\\n\"\n",
    "        \"- `descendant_matrix.npy`\\n\"\n",
    "        \"  Binary descendant-closure matrix where `M[i, j] = 1` iff node `j` is a descendant\\n\"\n",
    "        \"  of node `i` (including `i` itself).\\n\\n\"\n",
    "        \"- `taxonomy_vocab_with_unk.json`\\n\"\n",
    "        \"  Extension of `taxonomy_vocab.json` with one UNK token per rank\\n\"\n",
    "        \"  (`k:UNK, p:UNK, ..., s:UNK`), appended at the end.\\n\\n\"\n",
    "        \"- `descendant_matrix_with_unk.npy`\\n\"\n",
    "        \"  Descendant-closure matrix extended to include UNK nodes, enforcing\\n\"\n",
    "        \"  valid hierarchical transitions when taxonomy labels are missing.\\n\\n\"\n",
    "        \"- `rank_idx.npy`\\n\"\n",
    "        \"  Integer array mapping each taxonomy token to its taxonomic rank\\n\"\n",
    "        \"  (`0=k, 1=p, 2=c, 3=o, 4=f, 5=g, 6=s`). Required for per-rank prediction heads\\n\"\n",
    "        \"  and hierarchical masking.\\n\\n\"\n",
    "        \"## Notes\\n\\n\"\n",
    "        \"- UNK nodes are **model-level constructs** and do not alter the biological\\n\"\n",
    "        \"  structure of the base taxonomy.\\n\"\n",
    "        \"- Base and UNK-extended artifacts coexist to allow flexible experimentation\\n\"\n",
    "        \"  without recomputing the original tree.\\n\"\n",
    "    )\n",
    "\n",
    "print(\"Saved:\", readme_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42f55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_ontology_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee13826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys, json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4ab036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- project root & local modules ---\n",
    "PROJ_ROOT = \"/home/hernan_melmoth/Documents/phd_work/otu-taxa-foundation\"\n",
    "sys.path.append(os.path.join(PROJ_ROOT, \"src\"))\n",
    "\n",
    "from otu_taxa.taxonomy_parsing import (\n",
    "    load_sintax_table,\n",
    "    split_tax_path,\n",
    "    last_contiguous_valid_token,\n",
    "    token_depth,\n",
    "    RANKS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07eff1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_SINTAX_PATH     = /home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/taxonomy_reference/silva-138.2/vsearch_all_OTUs/repseqs_sintax_v123.txt\n",
      "CORRUPT_SINTAX_PATH  = /home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/taxonomy_reference/silva-138.2/vsearch_incomplete_genus_fromOTUS_predictions/repseqs_sintax_incomplete_genus.txt\n",
      "OUT_AFFECTED_PATH    = /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_genus_silva_sintax/dataset_full_top999/affected_otu_ids_from_removed_genus.txt\n",
      "[INFO] OTUs in common: 111870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting affected OTUs (genus corruption): 100%|██████████| 111870/111870 [00:00<00:00, 977422.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] affected OTUs: /home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training/level_97/silva-138.2/incomplete_genus_silva_sintax/dataset_full_top999/affected_otu_ids_from_removed_genus.txt\n",
      "[INFO] total affected OTUs: 12883\n",
      "[INFO] stats: {'baseline_no_label_skipped': 11042, 'corrupted_no_label_affected': 534, 'label_changed_affected': 12349, 'depth_changed_affected': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Configuration: dataset output directory \n",
    "# ============================================================\n",
    "DATASET_ROOT = \"/home/hernan_melmoth/Documents/phd_work/Microbeatlas_preprocess_training\"\n",
    "dataset_folder_name = \"dataset_full_top999\"\n",
    "\n",
    "dataset_dir = os.path.join(\n",
    "    DATASET_ROOT,\n",
    "    \"level_97\",\n",
    "    \"silva-138.2\",\n",
    "    \"incomplete_genus_silva_sintax\",\n",
    "    dataset_folder_name,\n",
    ")\n",
    "DATASET_DIR = Path(dataset_dir)\n",
    "assert DATASET_DIR.exists(), f\"Missing dataset_dir: {DATASET_DIR}\"\n",
    "\n",
    "# Save here (inside dataset_dir)\n",
    "OUT_AFFECTED_PATH = DATASET_DIR / \"affected_otu_ids_from_removed_genus.txt\"\n",
    "\n",
    "# ============================================================\n",
    "# Configuration: SINTAX inputs (genus corruption)\n",
    "# ============================================================\n",
    "\n",
    "# Baseline (non-corrupted) SINTAX\n",
    "BASE_SINTAX_PATH = Path(\n",
    "    \"/home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/\"\n",
    "    \"taxonomy_reference/silva-138.2/vsearch_all_OTUs/repseqs_sintax_v123.txt\"\n",
    ")\n",
    "assert BASE_SINTAX_PATH.exists(), f\"Missing baseline sintax: {BASE_SINTAX_PATH}\"\n",
    "\n",
    "# Corrupted (genus-removed) SINTAX from OTU predictions\n",
    "GENUS_CORRUPT_DIR = Path(\n",
    "    \"/home/hernan_melmoth/Documents/phd_work/Bio_ontology/MicrobeAtlas/level_97/\"\n",
    "    \"taxonomy_reference/silva-138.2/vsearch_incomplete_genus_fromOTUS_predictions\"\n",
    ")\n",
    "\n",
    "# According to your earlier screenshot, the file is named like this:\n",
    "CORRUPT_SINTAX_PATH = GENUS_CORRUPT_DIR / \"repseqs_sintax_incomplete_genus.txt\"\n",
    "\n",
    "# If the filename differs, switch to the correct one here:\n",
    "# CORRUPT_SINTAX_PATH = GENUS_CORRUPT_DIR / \"repseqs_sintax_incomplete.txt\"\n",
    "\n",
    "assert CORRUPT_SINTAX_PATH.exists(), f\"Missing genus-corrupted sintax: {CORRUPT_SINTAX_PATH}\"\n",
    "\n",
    "print(\"BASE_SINTAX_PATH     =\", BASE_SINTAX_PATH)\n",
    "print(\"CORRUPT_SINTAX_PATH  =\", CORRUPT_SINTAX_PATH)\n",
    "print(\"OUT_AFFECTED_PATH    =\", OUT_AFFECTED_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# Effective taxonomy extraction (contiguous-valid-prefix policy)\n",
    "# ============================================================\n",
    "\n",
    "def effective_label_and_depth(taxonomy_str: str):\n",
    "    \"\"\"\n",
    "    Effective taxonomy assignment under the contiguous-valid-prefix policy.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    label_token : str or None\n",
    "        Deepest contiguous valid taxonomy token.\n",
    "    depth : int\n",
    "        Rank depth index (0=kingdom ... 6=species), or -1 if unavailable.\n",
    "    \"\"\"\n",
    "    tokens = split_tax_path(taxonomy_str)\n",
    "    if not tokens:\n",
    "        return None, -1\n",
    "\n",
    "    label = last_contiguous_valid_token(tokens)\n",
    "    if label is None:\n",
    "        return None, -1\n",
    "\n",
    "    d = token_depth(label)\n",
    "    return label, (-1 if d is None else int(d))\n",
    "\n",
    "\n",
    "def build_otu_effective_map(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build mapping:\n",
    "        otu_id -> (label_token, depth, raw_taxonomy_string)\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates(\"otu_id\")\n",
    "    out = {}\n",
    "    for otu, tax in zip(df[\"otu_id\"].astype(str),\n",
    "                        df[\"taxonomy\"].fillna(\"\").astype(str)):\n",
    "        label, depth = effective_label_and_depth(tax)\n",
    "        out[otu] = (label, depth, tax)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Load SINTAX annotations\n",
    "# ============================================================\n",
    "base_df = load_sintax_table(str(BASE_SINTAX_PATH))\n",
    "corr_df = load_sintax_table(str(CORRUPT_SINTAX_PATH))\n",
    "\n",
    "base_map = build_otu_effective_map(base_df)\n",
    "corr_map = build_otu_effective_map(corr_df)\n",
    "\n",
    "common_otus = sorted(set(base_map) & set(corr_map))\n",
    "print(\"[INFO] OTUs in common:\", len(common_otus))\n",
    "\n",
    "# ============================================================\n",
    "# Identify affected OTUs (genus corruption)\n",
    "# ============================================================\n",
    "affected_otus = []\n",
    "stats = {\n",
    "    \"baseline_no_label_skipped\": 0,\n",
    "    \"corrupted_no_label_affected\": 0,\n",
    "    \"label_changed_affected\": 0,\n",
    "    \"depth_changed_affected\": 0,\n",
    "}\n",
    "\n",
    "for otu in tqdm(common_otus, desc=\"Detecting affected OTUs (genus corruption)\"):\n",
    "    base_label, base_depth, _ = base_map[otu]\n",
    "    corr_label, corr_depth, _ = corr_map[otu]\n",
    "\n",
    "    # Skip OTUs without a valid baseline taxonomy (cannot assess corruption impact)\n",
    "    if base_label is None:\n",
    "        stats[\"baseline_no_label_skipped\"] += 1\n",
    "        continue\n",
    "\n",
    "    # Corrupted lost its usable taxonomy label\n",
    "    if corr_label is None:\n",
    "        stats[\"corrupted_no_label_affected\"] += 1\n",
    "        affected_otus.append(otu)\n",
    "        continue\n",
    "\n",
    "    # Effective label changed\n",
    "    if corr_label != base_label:\n",
    "        stats[\"label_changed_affected\"] += 1\n",
    "        affected_otus.append(otu)\n",
    "        continue\n",
    "\n",
    "    # Effective depth changed (rare but tracked)\n",
    "    if corr_depth != base_depth:\n",
    "        stats[\"depth_changed_affected\"] += 1\n",
    "        affected_otus.append(otu)\n",
    "        continue\n",
    "\n",
    "# ============================================================\n",
    "# Save\n",
    "# ============================================================\n",
    "with open(OUT_AFFECTED_PATH, \"w\") as f:\n",
    "    for otu in affected_otus:\n",
    "        f.write(f\"{otu}\\n\")\n",
    "\n",
    "print(\"[SAVE] affected OTUs:\", OUT_AFFECTED_PATH)\n",
    "print(\"[INFO] total affected OTUs:\", len(affected_otus))\n",
    "print(\"[INFO] stats:\", stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5f652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_ontology_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
